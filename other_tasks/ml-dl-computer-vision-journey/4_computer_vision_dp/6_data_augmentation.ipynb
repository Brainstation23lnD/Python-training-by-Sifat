{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-17T13:27:36.458820Z",
     "start_time": "2025-08-17T13:27:36.151970Z"
    }
   },
   "source": [
    "\n",
    "import os, warnings\n",
    "\n",
    "from tensorflow_hub.keras_layer import keras\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "# reproducibility\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='gray')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load training and load data\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    './data/car_or_truck/train',\n",
    "    labels='inferred',\n",
    "    shuffle=True,\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    './data/car_or_truck/valid',\n",
    "    labels='inferred',\n",
    "    shuffle=True,\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "\n",
    "# Datapipeline\n",
    "def convert_to_float_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float_image)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float_image)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 files belonging to 2 classes.\n",
      "Found 5051 files belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T13:29:00.886415Z",
     "start_time": "2025-08-17T13:29:00.393779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load pretrained VGG16 base model (saved locally)\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    './models/cv-course-models/vgg16-pretrained-base'\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "# Define model\n",
    "model = keras.Sequential([\n",
    "    # ✅ Preprocessing layers\n",
    "    layers.RandomFlip('horizontal'),       # flip left to right\n",
    "    layers.RandomContrast(0.5),            # adjust contrast\n",
    "\n",
    "    # ✅ Base (pretrained)\n",
    "    pretrained_base,\n",
    "\n",
    "    # ✅ Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    evalidation_data=ds_valid,\n",
    "    epochs=10,\n",
    ")\n"
   ],
   "id": "b2b41348b24326e1",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling TFSMLayer.call().\n\n\u001B[1mCould not automatically infer the output shape / dtype of 'tfsm_layer_2' (of type TFSMLayer). Either the `TFSMLayer.call()` method is incorrect, or you need to implement the `TFSMLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor 'Placeholder:0' shape=(None, 224, 224, 3) dtype=float32>,) and kwargs: {} for signature: (*, input_1: TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_1')) -> Dict[['block5_pool', TensorSpec(shape=(None, 4, 4, 512), dtype=tf.float32, name='block5_pool')]].\nFallback to flat signature also failed due to: Tensor Tensor(\"Placeholder:0\", shape=(None, 224, 224, 3), dtype=float32) is not compatible with the shape this function was traced with. Expected shape (None, 128, 128, 3), but got shape (None, 224, 224, 3).\n\nIf you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.\u001B[0m\n\nArguments received by TFSMLayer.call():\n  • args=('<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_6>',)\n  • kwargs={'training': 'False'}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     28\u001B[39m x = layers.RandomFlip(\u001B[33m'\u001B[39m\u001B[33mhorizontal\u001B[39m\u001B[33m'\u001B[39m)(inputs)\n\u001B[32m     29\u001B[39m x = layers.RandomContrast(\u001B[32m0.5\u001B[39m)(x)\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m x = \u001B[43mpretrained_base\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m        \u001B[38;5;66;03m# TFSMLayer output\u001B[39;00m\n\u001B[32m     32\u001B[39m x = ExtractTensor()(x)        \u001B[38;5;66;03m# Extract tensor from dict\u001B[39;00m\n\u001B[32m     34\u001B[39m x = layers.Flatten()(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/MachineLearning/ml-dl-computer-vision-journey/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/MachineLearning/ml-dl-computer-vision-journey/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1184\u001B[39m, in \u001B[36mConcreteFunction._call_impl\u001B[39m\u001B[34m(self, args, kwargs)\u001B[39m\n\u001B[32m   1182\u001B[39m       \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_with_flat_signature(args, kwargs)\n\u001B[32m   1183\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m flat_err:\n\u001B[32m-> \u001B[39m\u001B[32m1184\u001B[39m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(  \u001B[38;5;66;03m# pylint: disable=raise-missing-from\u001B[39;00m\n\u001B[32m   1185\u001B[39m           \u001B[38;5;28mstr\u001B[39m(structured_err)\n\u001B[32m   1186\u001B[39m           + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mFallback to flat signature also failed due to: \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1187\u001B[39m           + \u001B[38;5;28mstr\u001B[39m(flat_err)\n\u001B[32m   1188\u001B[39m       )\n\u001B[32m   1190\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_with_flat_signature(args, kwargs)\n",
      "\u001B[31mTypeError\u001B[39m: Exception encountered when calling TFSMLayer.call().\n\n\u001B[1mCould not automatically infer the output shape / dtype of 'tfsm_layer_2' (of type TFSMLayer). Either the `TFSMLayer.call()` method is incorrect, or you need to implement the `TFSMLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor 'Placeholder:0' shape=(None, 224, 224, 3) dtype=float32>,) and kwargs: {} for signature: (*, input_1: TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_1')) -> Dict[['block5_pool', TensorSpec(shape=(None, 4, 4, 512), dtype=tf.float32, name='block5_pool')]].\nFallback to flat signature also failed due to: Tensor Tensor(\"Placeholder:0\", shape=(None, 224, 224, 3), dtype=float32) is not compatible with the shape this function was traced with. Expected shape (None, 128, 128, 3), but got shape (None, 224, 224, 3).\n\nIf you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.\u001B[0m\n\nArguments received by TFSMLayer.call():\n  • args=('<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_6>',)\n  • kwargs={'training': 'False'}"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
